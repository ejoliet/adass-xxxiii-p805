\documentclass[11pt,twoside]{article}

% Do NOT use ANY packages other than asp2014.
\usepackage{asp2014}

\aspSuppressVolSlug
\resetcounters

% References must all use BibTeX entries in a .bibfile.
% References must be cited in the text using \citet{} or \citep{}.
% Do not use \cite{}.
% See ManuscriptInstructions.pdf for more details
\bibliographystyle{asp2014}

% The ``markboth'' line sets up the running heads for the paper.
% 1 author: "Surname"
% 2 authors: "Surname1 and Surname2"
% 3 authors: "Surname1, Surname2, and Surname3"
% >3 authors: "Surname1 et al."
% Replace ``Short Title'' with the actual paper title, shortened if necessary.
% Use mixed case type for the shortened title
% Ensure shortened title does not cause an overfull hbox LaTeX error
% See ASPmanual2010.pdf 2.1.4  and ManuscriptInstructions.pdf for more details
\markboth{Joliet}{Running Roman pipelines in NASA cloud}

\begin{document}

\title{Running Roman pipelines in NASA cloud with Apache Airflow and Kubernetes}

% Note the position of the comma between the author name and the
% affiliation number.
% Authors surnames should come after first names or initials, eg John Smith, or J. Smith.
% Author names should be separated by commas.
% The final author should be preceded by "and".
% Affiliations should not be repeated across multiple \affil commands. If several
% authors share an affiliation this should be in a single \affil which can then
% be referenced for several author names. If only one affiliation, no footnotes are needed.
% See ManuscriptInstructions.pdf and ASP's manual2010.pdf 3.1.4 for more details
\author{Emmanuel~Joliet}
\affil{$^1$IPAC/Caltech, Pasadena, CA, USA; \email{ejoliet@caltech.edu}}

% This section is for ADS Processing.  There must be one line per author. paperauthor has 9 arguments.
\paperauthor{Emmanuel~Joliet}{ejoliet@ipac.caltech.edu}{}{California Institute of Technology}{IPAC}{Pasadena}{California}{91125}{USA}

% There should be one \aindex line (commented out) for each author. These are used to
% build up the author index for the Proceedings. The surname must come first, followed by
% initials. Note the use of ~ before each initial to control spacing.
% The \author entries (see above) have surname last. These \aindex entries have
% surname first.
% The Aindex.py command willl create them for you after you have constructed the \author
% The first entry should be the first author, for bold-facing the author index page-reference

%\aindex{Joliet,~E.}

\begin{abstract}
The Nancy Grace Roman Space Telescope is a NASA observatory to unravel dark energy and dark matter, search for and image exoplanets, and explore infrared astrophysics. This talk highlights the solution adopted by the Roman Science Support Center (SSC) team at Caltech/IPAC to run data pipelines using Airflow and Kubernetes in the NASA cloud.
\end{abstract}

% These lines show examples of subject index entries. At this stage these have to commented
% out, and need to be on separate lines. Eventually, they will be automatically uncommented
% and used to generate entries in the Subject Index at the end of the Proceedings volume.
% Don't leave these in! - replace them with ones relevant to your paper.
%\ssindex{FOOBAR!conference!ADASS 2019}
%\ssindex{FOOBAR!organisations!ASP}

% These lines show examples of ASCL index entries. At this stage these have to commented
% out, and need to be on separate lines. Eventually, they will be automatically uncommented
% and used to generate entries in the ASCL Index at the end of the Proceedings volume.
% The ascl.py command will scan your paper on possible code names.
% Don't leave these in! - replace them with ones relevant to your paper.
%\ooindex{FOOBAR, ascl:1101.010}


\section{The Roman mission}

The Nancy Grace Roman Space Telescope is a NASA observatory currently in development. It is designed to answer fundamental questions in the areas of dark energy, exoplanets, and astrophysics.  Roman will have two instruments, the Wide Field Instrument (WFI) and the Coronagraph Instrument. As the primary instrument, the WFI will observe the light from a billion galaxies over the mission and perform a microlensing survey of the inner Milky Way to find ~2,600 exoplanets. The Coronagraph Instrument will perform a technological demonstration preforming high contrast imaging of individual nearby exoplanets.  IPAC is supporting the science operations together with the Jet Propulsion Laboratory (JPL), The Space Telescope Science Institute (STScI) and the Goddard Space Flight Center (GSFC). Among several other items, the primary responsibilities for the \href{https://roman.ipac.caltech.edu}{Roman SSC\footnote{https://roman.ipac.caltech.edu}} at IPAC includes science data processing for the WFI microlensing survey and all spectroscopic observations in the NASA cloud.


\subsection{Key facts}

Key facts of the mission are:
\begin{itemize}
  \item Launch to L2 no later than May 2027
  \item Lifetime: 5 years
  \item Primary mirror is 2.4 meters (7.9 feet) in diameter
  \item Instruments
    \begin{itemize}
        \item Wide-Field Instrument (0.48um to 2.3um)
        \item Coronagraph Instrument (0.55um to 0.86um)
    \end{itemize}
  \item Roman SSC at IPAC to produce high level sci data products
\end{itemize}

\subsection{Roman SSC responsibilities}

The SSC is responsible for running two higher level science data processing pipelines
in the NASA Mission Cloud Platform. These include the Microlensing pipeline and the
Spectroscopy pipeline for data taken with the grism or prism filers (GDPS).

The WFI Microlensing Science Operations System (MSOS) processing pipeline will produce daily light curves, seasonal objects and events catalogs among other products (\~200 million objects), Microlensing events (see simulated event in figure \ref{ex_fig1}) catalog, Light Curves.

The WFI Grism and Prism Data Processing System (GDPS) pipeline will produce decontaminated 2D and 1D extracted spectra and spectral redshifts among other products (see example of spectral fitting in figure \ref{ex_fig2}). 

These higher level products will support the Galactic Bulge Time Domain Survey and High Latitude Wide Area, High Latitude Time Domain and Guest Observer surveys.

Other SSC main systems are the Coronagraph Instrument Operations and Data Management System, Roman Telescope Proposal System, and Community Engagement.

Data volumes estimates are:

\begin{itemize}
\item MSOS - 5 TB/daily  ~ 2PB over mission lifetime (6 seasons of ~62 days each) 
\item GDPS - 1.5TB/daily during survey (unsure since TBD observations)
\item CGI - 1TB over tech demo
\end{itemize}

\articlefigure[width=.5\textwidth]{P805_f1.eps}{ex_fig1}{Simulated Roman microlensing event (2 seasons) with a planetary anomaly (\citet{2019ApJS..241....3P})}

\articlefigure{P805_f2.eps}{ex_fig2}{Example of redshift PDF visualization (top) and spectral fitting (bottom) in the 1D pipeline. In the bottom panel, the data are shown in blue and fit to the continuum and the spectral features (along with the uncertainty) are shown in red.  The fit to the emission lines are used to generate the zPDF shown in the top plot, here with a strong peak in the solution at a redshift z~1.55.  A weaker, secondary maximum is also seen at z~1.48.}

\section{NASA Cloud platform}

The NASA Mission Cloud Platform (NMCP) uses AWS\footnote{https://aws.amazon.com} services to run mission work including running the science pipelines. AMIs, VPCs, ACL and few other cloud related environment and services are managed by NMCP. Roman SSC sets the roles, compute services and manages deployments and data. The Docker images are stored and managed from AWS Elastic Container Registry (ECR) service.
The containers are provisioned and orchestrated by Kubernetes cluster using the AWS Elastic Kubernetes Service (EKS).
The Roman science products files are stored and indexed in AWS Simple Storage Service (S3) buckets.
Databases Aurora RDS PostgreSQL are used to host the Airflow metadata\footnote{https://docs.astronomer.io/learn/airflow-components\#core-components} and pipeline processing needs.

\section{Apache Airflow in the cloud}

The Roman SSC science data processing pipeline tasks are scheduled and run in a Kubernetes cluster (AWS EKS) using the Apache Airflow\footnote{https://airflow.apache.org} scheduler and UI dashboard. The task workflows are defined as Direct Acyclic Graphs (DAGs) using the Airflow task API. The infrastructure-as-code scripts (CloudFormation stacks\footnote{https://aws.amazon.com/cloudformation/} and Helm charts are used to manage software and services deployments into Kubernetes such as Roman software containers, Apache Airflow, Grafana and Prometheus.
Docker images registry (AWS ECR) helps storing, distributing and versioned the science software under GitHub.
The Airflow \emph{KubernetesPodOperator}\footnote{https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/operators.html} operator is used to define the task and its resources.
Node group consists of EC2s ‘aml2’, with ability to scale vertically and horizontally

\subsection{Software engineering}

Roman SSC uses a GitOps approach for defining and deploying the infrastructure and resources. We apply DevOps best practices to a CI/CD chain, with version control and infrastructure-as-code automation. Our Python ecosystem includes asdf, astropy, scipy, pydantic, dask, boto3, matplotlib, pytest/tox, and Airflow API, among others. The C/C++ codebase makes use of numerical and test unit libraries.
The Code, DAGs and AWS scripts to support running the pipelines are under Configuration Management in IPAC private GitHub repositories.
Docker images are used as a release artifacts to be distributed in EKS cluster and run as PODs.
Security issues and Common Vulnerabilties and Exposures (CVEs) are scanned on GitHub code and on containers hosted in AWS ECR with Snyk tool.
A Jenkins server on an EC2 instance is running builds, tests on code changes and releases.
The Apache Airflow frontend UI allows operators to monitor and troubleshoot the data pipelines, providing insights into DAGs and DAG runs.


\section{Conclusion}

Roman SSC at IPAC/Caltech uses Apache Airflow scheduler and frontend UI to define, deploy, run and monitor pipeline tasks on a Kubernetes cluster in the NASA cloud, making use of several other AWS services for storage, data transfer and scalability purposes.


\acknowledgements I would like to thank Patrick Lowrance and Keto Zhang from Roman SSC at IPAC/Caltech who reviewed the poster/paper.

\bibliography{P805}  % For BibTex

% if we have space left, we might add a conference photograph here. Leave commented for now.
% \bookpartphoto[width=1.0\textwidth]{foobar.eps}{FooBar Photo (Photo: Any Photographer)}

\end{document}
